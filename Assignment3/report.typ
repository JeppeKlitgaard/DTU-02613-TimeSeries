#import "@preview/physica:0.9.4": super-T-as-transpose
#import "@preview/codly:1.2.0": *
#import "@preview/codly-languages:0.1.1": *
#import "utils.typ": mathformatter, mref

#set page(
  paper: "a4",
  numbering: "1/1",
  header: context {
    if(counter(page).get().at(0)== 1) [

    ] else [
    #set align(center)
    #set text(10pt, fill: gray)
      02417 Times Series Analysis - Assignment 3
  ]
  }
)

// Font fix because FruityFeedback is trash
#set text(font: "STIX Two Text")
#show math.equation: set text(font: "STIX Two Math")

#show: codly-init.with()
#codly(languages: codly-languages)


#set heading(numbering: "1.1.a")
#set math.equation(numbering: "(1)", supplement: [Eq.])
#show: super-T-as-transpose
#set table.header()

#let vv = mathformatter(underbars: 0, bold: true, upright: false)
#let mm = mathformatter(underbars: 0, bold: true, upright: true)

#let Cov = math.op("Cov")
#let Var = math.op("Var")

///////////////////////////////////////////////////////////////////////////////

#align(center, text(17pt)[
  *02417 Times Series Analysis - Assignment 3*
])

Authors:
- Jeppe Klitgaard `<s250250@dtu.dk>`
- Yunis Wirkus `<s250700@dtu.dk>`

Date: 2025-04-21

#pagebreak()

= Simulations <sec:1_stability>

We are given an AR(2) process ${X_t}$ with residual term $Îµ_t$ arising from a stochastic process ${Îµ_t} âˆˆ ğ’©(0, Ïƒ_Îµ^2=1)$ :
$
  X_t + Ï•_1 X_(t-1) + Ï•_2 X_(t-2) = Îµ_t
$ <eq:1_ar2>

Our implementation will be based on the `statsmodels` library in Python, which offers an implementation of the `SARIMAX` (Seasonal AutoRegressive Integrated Moving Average with eXogenous regressors) model.

Importantly, the `SARIMAX` model follows an alternative formulation of the model:
$
  y_t = Ï†_1 y_(t-1) + Ï†_2 y_(t-2) + Îµ_t
$ <eq:1_sarimax_statsmodels>

Where we have used the two different variants of the letter phi to denote the different formulations.
Comparing @eq:1_ar2 and @eq:1_sarimax_statsmodels we find that the two formulations are equivalent given a sign change:
$
  Ï†_1 = -Ï•_1, wide Ï†_2 = -Ï•_2
$ <eq:1_phi_sign_change>

== Realisations

=== 1.1 & 1.2
We simulate the given process 5 times using the ```SARIMAX``` module with $n=200$ observations and the coefficients set to: $Ï•_1 = -0.6$ and $Ï•_2 = 0.5$

#figure(
  // image("img/blabla.png"),
  [],
  caption: [Simulation and Autocorrelation function of AR(2) process with $Ï•_1 = -0.6, Ï•_2 = 0.5$.],
) <fig:1_1_sim-acf>

- plot Simulation and ACF together
- plot "empirical" ACF and rho(k) for k lag in {0, ..., 30}
- comment on the result

=== 1.3

- new simulations & ACFs with $Ï•_1 = -0.6$ and $Ï•_2 = -0.3$
- comment on each, focus on stationarity

=== 1.4

- with $Ï•_1 = 0.6$ and $Ï•_2 = -0.3$

=== 1.5

- with $Ï•_1 = -0.7$ and $Ï•_2 = -0.3$

=== 1.6

- with $Ï•_1 = -0.75$ and $Ï•_2 = -0.3$

=== 1.7

- comment on: is it enough to plot the ACF or is the time-series helpful?
- ...in @fig:1_1_sim-acf we can see...

#pagebreak()

= Predicting Monthly Solar Power <sec:2_predicting_monthly_solar_power>

We are given a seasonal AR model:
$
  (1 + Ï•_1B)(1 + Î¦_1B^12)(log(Y_t)-Âµ) = Îµ_t
$ <eq:2_seasonal_ar>

where $Y_t$ is the monthly energy from the plant in MWh, ${Îµ_t}$ is a white-noise process with variance $Ïƒ_Îµ^2$ . The parameters $Ï•_1 = âˆ’0.38$, $Î¦_1 = âˆ’0.94$ and $Âµ = 5.72$ are assumed to be known. Based on 36 observations, it is found that $Ïƒ_Îµ^2 = 0.22^2$.

== Forecasting and Residuals

=== Reformulation

Using a substitution $X_t = log(Y_t) - Î¼$ we can rewrite the model, @eq:2_seasonal_ar, as:
$
  (1 + Ï•_1B)(1 + Î¦_1B^12)X_t = Îµ_t
$ <eq:2_rewritten_ar_1>

We are then asked to rewrite the model in order to calculate the residuals $hat(Îµ)_(t+1|t)$,
which we understand to be the estimated one-step-ahead forecast error, such that $hat(Îµ)_(t+1|t) â‰” X_(t+1) - hat(X)_(t+1)$.
Recalling $B^q X_t â‰” X_(t-q)$, we expand @eq:2_rewritten_ar_1 to find:
$
  (1 + Ï•_1B)(1 + Î¦_1B^12)X_t &= Îµ_t\
  X_t + Ï•_1 B X_t + Î¦_1 B^12 X_t + Ï•_1 Î¦_1 B^13 X_t &= Îµ_t\
  X_t + Ï•_1 X_(t-1) + Î¦_1 X_(t-12) + Ï•_1 Î¦_1 X_(t-13) &= Îµ_t\
$

Multiplying through by $B^(-1)$ we find:
$
  X_(t+1) + Ï•_1 X_t + Î¦_1 X_(t-11) + Ï•_1 Î¦_1 X_(t-12) &= Îµ_(t+1)\
$

Solving for $X_(t+1)$ we find:
$
  X_(t+1) = Îµ_(t+1) - Ï•_1 X_t - Î¦_1 X_(t-11) - Ï•_1 Î¦_1 X_(t-12)\
$ <eq:2_forecast_1>

We then construct the _optimal predictor_ for $X_(t+1)$, @Madsen_2008[eq.~5.139]:
$
  hat(X)_(t+1)
  &= ğ”¼[X_(t+1)|X_t, X_(t-1), â€¦]\
  &= -hat(Ï•)_1 X_t - hat(Î¦)_1 X_(t-11) - hat(Ï•)_1 hat(Î¦)_1 X_(t-12) wide wide ğ”¼[Îµ] = 0\
$

Where we have used the fact that the $Îµâˆ¼ğ’©(0, Ïƒ^2_Îµ)$.
Thus the one-step-ahead forecast error becomes:
$
  hat(Îµ)_(t+1|t) &= X_(t+1) - hat(X)_(t+1)\
  &= X_(t+1) + hat(Ï•)_1 X_t + hat(Î¦)_1 X_(t-11) + hat(Ï•)_1 hat(Î¦)_1 X_(t-12)\
$ <eq:2_1_prediction_error>

=== Verifying Residuals in Dataset <sec:2_1_a>

As already noted in the section above, we assume that the residuals are independent and identically distributed (i.i.d.)
with a zero-mean normal distribution.

We can verify that this is indeed the case by constructing the
appropropriate seasonal AR model using the `SARIMAX` class from `statsmodels`.
Again we take careful notice of the signs of the parameters $Ï•_1$, $Î¦_1$, both
of which must be negated to match the convention of the `SARIMAX` class.

Utilising the built-in `plot_diagonstics` function of the fitted model, we produce @fig:2_residual_analysis.

#figure(
  image("output/2_residual_analysis.png"),
  caption: [Residual analysis of the solar power dataset using $Ï•_1=-0.38$, $Î¦_1=-0.94$ and $Ïƒ_Îµ^2=0.22^2$
  in the notation established by @eq:2_rewritten_ar_1.
  Note that the residual analysis is performed on the transformed data $X_t = log(Y_t) - Î¼$.],
) <fig:2_residual_analysis>

By inspection of @fig:2_residual_analysis we find no evidence that the residuals violate
the assumption of i.i.d. with a zero-mean normal distribution.
In particular, we find that the standardised residuals do not exhibit strong systematic patterns,
although the first summer (observations 5-10) does appear to be skewed slightly positive in the residuals.
Additionally, we find the residuals to be well-described by a normal distribution as seen in the Q-Q plot and histogram.

One could carry out a Lljung-Box test to further substantiate this claim, but we find that
this is not nececssary in this case.

== Forecasting

Using the same model that we fitted in @sec:2_1_a, we produce a 12 month forecast ($k=12$)
using the `forecast` method.

Importantly, the forecasted data must be transformed back into the original scale of the dataset:
$
  X_t & := log(Y_t) - Î¼ wide wide &"Forward"\
  Y_t & = e^(X_t + Î¼) wide wide &"Backward"\
$ <eq:2_transformations>

#let data_2_2= csv("output/2_2.csv")

#figure(
  table(
    columns: data_2_2.at(0).len(),
    table.header([*Time*], [*Power, $bold(Y_t)$ \[MWh*\]], $bold(X_t)$),
    ..data_2_2.slice(1).flatten(),
  ),
  caption: [Twelve month forecast using model given in @eq:2_seasonal_ar.]
) <table:2_2_forecast>

Which we can plot alongside the original data to produce @fig:2_2_forecast.
#figure(
  image("output/2_2_forecast.png"),
  caption: [Twelve month forecast using model given in @eq:2_seasonal_ar.]
) <fig:2_2_forecast>

We find that the forecasted data matches our intuition of the data well and
follows the seasonal pattern observed in the historical data of power generation.

== Prediction Intervals

We now wish to consider the _variance_ in our _predictions_, or rather we seek to
obtain the _variance of the prediction error_, @eq:2_1_prediction_error:
$
  Var(hat(Îµ)_(t+1|t)) = Var(X_(t+1) - hat(X)_(t+1))\
$

In order to carry out this calculation, we convert our process to a Moving-Average (MA) process:
$
  X_t
  &= Îµ_t/((1 + Ï•_1B)(1 + Î¦_1B^12)) wide wide â‡” &&#mref("eq:2_seasonal_ar")\
  &= (1 + Ïˆ_1 B + Ïˆ_2 B^2 + â€¦)Îµ_t+ ... wide wide && "Definition of MA process"\
$ <eq:2_ma_process_1>

From @eq:2_ma_process_1 we recover the constraint:
$
  (1 + Ïˆ_1 B + Ïˆ_2 B^2 + â€¦)(1 + Ï•_1 B)(1 + Î¦_1 B^12) &= 1\
  (1 + Ïˆ_1 B + Ïˆ_2 B^2 + â€¦)(1 + Ï•_1 B + Î¦_1 B^12 + Ï•_1 Î¦_1 B^13) &=1\
$ <eq:2_ma_process_constraints>

Which imposes that all coefficients of the power series of $B$ must vanish.
Comparing powers of $B^i$ we find the following constraints on the weights
$Ïˆ_i$ of the transfer function:
$
  Ïˆ_i = cases(
    (-Ï•_1)^i wide & 1 â‰¤ i â‰¤ 11\
    (-Ï•_1)^i - Î¦_1(-Ï•_1)^(i-12) wide & 12 â‰¤ i â‰¤ 23\
    â‹® wide & â‹®
  )
$ <eq:2_ma_weights>

Using our MA formulation we again consider the expression of $X_(t+1)$ using the treatment in @Madsen_2008[sec:~5.7.1]:
$
  X_(t+k) = Îµ_(t+k) + Ïˆ_1 Îµ_(t+k-1) + â€¦ + Ïˆ_k Îµ_(t) + Ïˆ_(k+1) Îµ_(t-1) + â€¦
$

We consider the expectation value of the residual $Îµ_(t+k)$.
For past observations, when $k â‰¤ 0$, have a realisation of the residual and thus this will be our expected value.
For future observations, when $k > 0$,
we have no realisation of the residual and thus the expected value is the mean of the distribution of $Îµ$,
which we recall to be zero:
$
  ğ”¼[Îµ_(t+k)|X_t, X_(t-1), â€¦] = cases(
    Îµ_(t+k) wide & k â‰¤ 0\
    0 wide & k > 0
  )
$ <eq:2_residual_expectation>

From which we can obtain our $k$-step predictions, $X_(t+k|t)$:
$
  X_(t+k|t)
  &= ğ”¼[X_(t+k)|X_t, X_(t-1), ...]\
  &= cancel(ğ”¼[Îµ_(t+k)|X_t, X_(t-1), ...] + Ïˆ_1 ğ”¼[Îµ_(t+k-1)|X_t, X_(t-1), ...] + â€¦) wide wide && â‡ #mref("eq:2_residual_expectation")\
  &quad + Ïˆ_k ğ”¼[Îµ_(t)|X_t, X_(t-1), ...] + Ïˆ_(k+1) ğ”¼[Îµ_(t-1)|X_t, X_(t-1), ...] + â€¦\
  &= Ïˆ_k Îµ_(t) + Ïˆ_(k+1) Îµ_(t-1) + â€¦\

$

Using our previous definition of the prediction error, @eq:2_1_prediction_error, we find:
$
  hat(Îµ)_(t+k|t)
    &= X_(t+k) - hat(X)_(t+k)\
    &= Îµ_(t+k) + Ïˆ_1 Îµ_(t+k-1) + â€¦ + cancel(Ïˆ_k Îµ_(t) + Ïˆ_(k+1) Îµ_(t-1) + â€¦)\
    &quad cancel(-(Ïˆ_k Îµ_(t) + Ïˆ_(k+1) Îµ_(t-1) + â€¦))\
    &= Îµ_(t+k) + Ïˆ_1 Îµ_(t+k-1) + â€¦ + Ïˆ_(k-1) Îµ_(t+1)
$ <eq:2_prediction_error_k>

Where the variance of this prediction error at time $t+k$ is given by:
$
  Ïƒ^2_(k)
  &= Var(hat(Îµ)_(t+k|t))\
  &= Var(Îµ_(t+k) + Ïˆ_1 Îµ_(t+k-1) + â€¦ + Ïˆ_(k-1) Îµ_(t+1))\
  &= Var(Îµ_(t+k)) + Ïˆ_1^2 Var(Îµ_(t+k-1)) + â€¦ + Ïˆ_(k-1)^2 Var(Îµ_(t+1))\
$

We consider that $hat(Îµ)_(t+k|t) âˆ¼ ğ’©(0, Ïƒ^2_Îµ)$ and thus find $Var(Îµ_(t+k)) = Ïƒ^2_Îµ$ for all $k>0$.
Plugging this into @eq:2_prediction_error_k yields:
$
  Ïƒ^2_(k) = Ïƒ^2_Îµ (1 + Ïˆ_1^2 + â€¦ + Ïˆ_(k-1)^2)
$

This enables us to calculate the $(1-Î±)$ confidence interval of our $k$-step predictions:
$
  hat(X)_(t+k|t) Â± u_(Î±\/2) Ïƒ_(k)
  = hat(X)_(t+k|t) Â± u_(Î±\/2) Ïƒ_Îµ sqrt(1 + Ïˆ_1^2 + â€¦ + Ïˆ_(k-1)^2)\
$ <eq:2_prediction_interval>

Where $u_(Î±\/2)$ is the $Î±\/2$ quantile of the standard normal distribution.
For $Î± = 5%$ we find $u_(Î±\/2) â‰ˆ 1.96$.

With this, we are able to calculate the prediction intervals for our forecasted data
using by leveraging the expression for the weights $Ïˆ_i$ in @eq:2_ma_weights,
which yields the 95% prediction intervals shown in @fig:2_3_forecast_ci.

#figure(
  image("output/2_3_forecast_ci.png"),
  caption: [Twelve month forecast using model given in @eq:2_seasonal_ar with 95% prediction intervals.]
) <fig:2_3_forecast_ci>

We note that the for $1 <= k <= 11$ the seasonal component does not contribute to the prediction error
as also hinted in the assignment description,
but for $k=12$ we find a linear dependence on the coefficient of the seasonal component. $Î¦_1$.
This is a significant difference when contrasted against not including the seasonal component.


== Forecast Commentary

We consider the forecast found in @fig:2_3_forecast_ci to be a relatively accurate description
of the expected power generation of the solar plant during the year of 2011.
In the original dataset we observe a slight decline in the peak power generation as a function of time,
which is also observed in the forecast.
This can be attributed to expected degradation of the photo-voltaic solar panels over time.

Notably, the prediction intervals are not symmetric over the expected value,
which is a result of the non-linear transformation of the data as described in @eq:2_transformations.

Additionally, we observe that the prediction intervals are quite wide,
which again can be understood in part by referring to the exponential transformation of the data.
Additionally we observe large variations in the shape of the observations of the 3 year history of the solar plant,
which pushes up the estimated variance of the residuals, $Ïƒ_Îµ^2 = 0.22^2$.
This strongly influences the width of the prediction intervals, which is particularly notable
at power generation observations due to the transformation.
This is simply a consequence of linearising the data in order to fit it to our linear model.

From inspection, we find that the prediction intervals are likely too wide during the summer months
where power generation is at its peak, due to overly large effect of the variance during the winter months on the residual error estimates.

The implementation of the prediction intervals can be found in the attached Jupyter Notebook `JK_2.ipynb`.

#bibliography("report.bib")
